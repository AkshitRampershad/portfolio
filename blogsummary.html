<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Addressing Bias in AI</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
  <style>

.top-image {
      width: 90%;
      height: 50%;
      display: block;
      margin: 10px auto;
    }

    /* Reset default margin and padding */
    body, h1, h2, h3, p, ul, li, form {
      margin: 0;
      padding: 0;
    }

    /* Set background color and text color */
    body {
      background-color: black;
      background-image: url("images/background2.png");
      background-repeat: no-repeat;
      background-size: cover;
      background-attachment: fixed;
      color: whitesmoke;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif
    }

   /* Style header and navigation */
   header {
      background-color: black;
      padding: 35px;
      display: flex;
      justify-content: center; /* Align navigation in the middle */
    }

    nav ul {
      list-style-type: none;
      display: flex;
      justify-content: center; /* Align list items in the middle */
    }
    nav ul li {
      display: inline;
      margin-right: 15px;
      margin-bottom: -70px;
    }

    nav ul li a {
      color: #ffffff;
      text-decoration: none;
      text-align: center;
      font-weight: bold;
      font-size: large;
      transition: all 0.3s ease;
      white-space: nowrap; /* Prevent line breaks */
    }

    nav ul li:not(:last-child) a {
      margin-right: 50px; /* Add space between each word */
    }

    nav ul li a:hover {
      color: #007bff;
    }

    /* Style sections */
    section {
      padding: 20px 0;
    }

    .container {
      width: 80%;
      margin: 0 auto;
    }


/* styles.css */
#subscribe-form {
  display:flex;
  justify-content: center;
  align-items: center;
  height: 20vh; /* Adjust this value based on your layout */
  margin-bottom: -90px; /* Add or adjust this line to control the space below the button */

}

#subscribe-form button {
  background-color: #007bff;
  color: white;
  padding: 10px 50px;
  border: none;
  border-radius: 5px;
  cursor: pointer;
  font-size: 14px;
  font-weight: bold;
  margin-top: -10px;
}

#subscribe-form button:hover {
  background-color: blue;
}

    /* code for image workflow */

    .image-container {
      display: flex;
      flex-direction: row;
      align-items: center;
      margin-bottom: -50px;
      padding: 0px;
      margin-left: 5px;
    }
    
    .description {
      padding: 15px;
      margin-left: 120px;
      margin-right: auto;
      text-align: left;

    }
    
    .image {
      flex: 2px;
      text-align: left;
    }
    
    .image img {
      max-height: 700px;
      max-width: 100%;
      display: block;
      padding-left: 10px;
      padding-right: 40px;
    }

    /* Add styling for the blog article */
    .blog-article {
      margin-bottom: 20px;
    }

    .blog-article h3 {
      margin-bottom: 10px;
    }

    .blog-date {
      color: #777;
      font-style: italic;
    }
    
    .social-media-card {
      background-color: transparent;
      border: none;
      border-radius: 5px;
      padding: 15px;
      margin-top: 20px;
    }

    .share-text {
      margin-bottom: 10px;
      font-weight: normal;
      font-size: 20px;
      color: whitesmoke;
      text-align: center;
    }

    .social-media-icons {
      display: flex;
      justify-content: center;
    }

    .social-media-icons a {
      display: inline-block;
      margin-right: 50px;
      margin-left: 50px;
      color: #007bff;
      font-size: 35px;
      transition: color 0.3s ease;
    }

.social-media-icons a:hover {
  color: blue;
}

/*comment section*/
body {
  font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
}

    h1 {
  text-align: center;
}

#comment-container {
  margin-top: -90px;
  padding: 130px;

}

#comment-form {
  display: flex;
  flex-direction: column;
  margin-bottom: 20px;
}

#comment-form input,
#comment-form textarea {
  margin-bottom: 5px;
  padding: 15px;
}

#comment-form button {
  padding: 8px 16px;
  background-color: #007bff;
  color: #ffffff;
  border: none;
  cursor: pointer;
  font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
}

#comment-list {
  border: none;
  padding: 5px;
}

.comment-item {
  margin-bottom: 10px;
}

.comment-item strong {
  font-weight: bold;
}

.comment-item span {
  margin-left: 10px;
  color: #777;
}

   /* Style footer */
   footer {
      background-color: black;
      padding: 25px;
      text-align: center;
      color: #ffffff;
      font-size: 15px;
    }     

    /* Styles for mobile devices */

@media screen and (max-width: 768px) {
  .top-image {
    width: 100%;
    height: auto;
  }

  header {
    padding: 25px;
  }

  nav ul li {
    margin-right: -10px;
    margin-left: -4;
    margin-bottom: 0;
  }

  .description {
    margin-left: 20px;
  }

  .image-container {
    flex-direction: column;
  }

  .image img {
    max-height: 400px;
    padding: 0;
    margin: 10px auto;
  }

  #subscribe-form {
    height: auto;
    margin-bottom: 0;
  }

  #subscribe-form button {
    padding: 8px 30px;
    font-size: 12px;
    margin-bottom: 30px;
    margin-top: 10px;
  }

  .social-media-icons a {
    margin-right: 30px;
    margin-left: 30px;
    font-size: 30px;
  }

  #comment-container {
    margin-top: 0;
    padding: 20px;
  }

  #comment-form input,
  #comment-form textarea {
    padding: 10px;
  }

  #comment-form button {
    padding: 6px 12px;
    font-size: 14px;
  }

  footer {
    padding: 15px;
    font-size: 12px;
  }
}

    /* Media Queries */
  @media (max-width: 768px) {
    h2 {
      font-size: 24px;
  
    }

    img {
      width: 100%;
      margin: 50px;

    }

    div[style*="display: flex; align-items: center;"] {
      flex-direction: column;
    }

    div[style*="display: flex; align-items: center;"] img {
flex-direction: column-reverse;   

}
 .social-media-card {
        text-align: center;
      margin-top: -50px;
      margin-bottom: 10px;
    }
  }

/* Media query for smaller screens */
@media screen and (max-width: 768px) {
  #comment-container {
    padding: 50px;
    margin-top: -90px;
  }
}


</style>
</head>
<body>
  <header>
    <nav>
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="projectsummary.html">Projects</a></li>
        <li><a href="blogstab.html">Blog</a></li>
      </ul>
    </nav>
  </header>
  <section id="blog">
    <div class="container">
      <br><h2 style="text-align: center;">Designing AI for All: Addressing Bias in Artificial Intelligence Systems</h2><br><br>
      <img src="images/blog1.jpg" alt="Top Image" class="top-image">
      <article class="blog-article">
        <h3></h3>
        <p class="blog-date">Published on June 15, 2023</p> <br> 
<p style="text-align:justify;">   <font size="4px">
I found the article titled "Designing AI for All: Addressing Bias in Artificial Intelligence Systems" to be very interesting because it highlights the issue of bias in AI systems and the importance of designing AI algorithms that are fair and unbiased. The article explains how biases can be inadvertently introduced into AI systems and the potential consequences of these biases. It also provides insights into the steps that can be taken to mitigate bias and promote fairness in AI systems. As an aspiring data analyst, understanding and addressing bias in AI systems is crucial for me to ensure that the insights and recommendations I provide are unbiased and ethical.
  <br><br>
  Artificial intelligence (AI) is revolutionizing our lives, from virtual assistants like Siri and Alexa to self-driving cars. However, the pervasive nature of AI does not make it immune to bias. Bias in AI refers to the systematic skewing of predictions and decisions in favor of or against particular groups. This bias can stem from the training data, algorithms, and the biases of designers and developers. Addressing bias is crucial to ensure fairness, integrity, and equitable outcomes in AI systems.
</p>  </font>
<p><br><br>
    <h2 style="text-align: center;"> The Consequences of Bias in AI:</h2><br>
        <p style="text-align: justify;"><font size="4px">
          Bias in AI systems can have far-reaching consequences. Flawed or misleading insights and conclusions can emerge when AI systems are biased. This can lead to inadequate options that impact individuals and organizations. Moreover, biased AI systems can perpetuate existing societal inequities, exacerbating unfairness and inequality. Trust in AI technology is eroded when it contributes to biased outcomes. To address bias effectively, a careful approach is needed, encompassing data collection, diverse development teams, regular audits, and ongoing training.
        </p><br><br></font>
        <h2 style="text-align: center;">Challenges in Addressing Bias:</h2><br>
        <p style="text-align: justify;"><font size ="4px">
          Detecting bias in AI systems can be challenging due to their complexity and opacity. To overcome this challenge, it is essential to have diverse teams working on AI development while prioritizing ethical considerations. Ensuring fairness and integrity in AI design and implementation requires proactive bias mitigation from the early stages of development. Developing algorithms that incorporate fairness considerations can help minimize bias. Techniques such as data preprocessing, algorithm adjustments, and fairness evaluation metrics contribute to bias reduction. Additionally, transparency measures, accessibility of data and algorithms, and clear guidelines and regulations promote fair and responsible AI use.
        </p></font>
</p>
</article>
</div>
<div id="new-section">
    <div class="image-container">
      <div class="description">
                <h2>Step to mitigate bias in AI Systems</h2>
                <br>
                <p style="text-align: justify;"><b><li><font size="4">Identify Bias:</font></b> Analyze the model and data for potential biases.</li></p><br>

                <p style="text-align: justify;"><b><li><font size="4"> Collect Representative Data:</font></b> Ensure a diverse dataset the target population.</li></p><br>
                
                <p style="text-align: justify;"><b><li><font size="4"> Data Preprocessing:</font></b> Address biases through techniques like augmentation or balancing.</li></p><br>
                
                <p style="text-align: justify;"><b><li><font size="4"> Feature Selection:</font></b> Modify or remove biased features; introduce fair representation.</li></p><br>
                
                <p style="text-align: justify;"><b><li><font size="4"> Define Fairness Metrics:</font></b> Establish metrics aligned with values and objectives.</li></p><br>
                
                <p style="text-align: justify;"><b><li><font size="4"> Regularize Model Training:</font></b> Penalize biased behavior through regularization techniques.</li></p><br>
                
                <p style="text-align: justify;"><b><li><font size="4"> Evaluate Performance:</font></b> Assess fairness across different demographic groups.</li></p><br>
                
                <pstyle="text-align: justify;"><b><li><font size="4"> Mitigate Bias:</font></b> Apply specific techniques to reduce bias if detected.</li></p><br>
                
                <pstyle="text-align: justify;"><b><li><font size="4"> Monitor and Update:</font></b> Continuously monitor and update the model to address bias.</li></p><br>
                
                <pstyle="text-align: justify;"><b><li><font size="4"> External Reviews:</font></b> Engage experts for independent audits and insights.</li></p><br>
            </div>
              <div class="image">
                <img src="images/workflow.jpg" alt="Vertical Image">
              </div>
            </div>
          </div>          
  </section><br>  
  <section id="blog">
    <div class="container">
          <article class="blog-article">
            <h2 style="text-align: center;" >The Impact of Bias on Organizations:</h2><br>
            <p style="text-align: justify;"> <font size="4px">
             AI bias can significantly affect a company's data analytics, resulting in skewed insights, flawed decision-making, and unintended consequences. Amazon's recruiting tool serves as a real-life example of AI bias in data analytics. The tool, trained on historical resumes mostly from male applicants, exhibited bias against female candidates. As a result, the algorithm associated male candidates with higher qualifications, penalizing resumes with indications of female gender. The biased system undermined fairness and objectivity in the recruitment process. To avoid such situations, organizations need to be aware of the potential biases in their data and develop robust processes to identify and mitigate bias in AI systems.
            </p><br><br> </font>
          
            <h2 style="text-align: center;"> Example: Bias in Healthcare AI</h2><br>
            <div style="display: flex; align-items: center;">
              <img src="images/amazonbias.webp" alt="vertical-align" height="220" width="290" style="margin-right: 50px;">
              <p style="text-align: justify;"> <font size="4px">
                The healthcare sector faces significant risks when it comes to biased AI systems. Diagnostic decision-making, for instance, is an area where bias can harm patients. Biased AI systems used for diagnosing illnesses may lead to misdiagnosis or delayed treatment for certain groups. If AI systems are trained on data predominantly from specific demographics, accuracy in diagnosing illnesses for other racial or ethnic groups may suffer. To mitigate bias, involving diverse perspectives in the development process is vital. Engaging patients and healthcare providers from diverse backgrounds ensures AI systems are designed to work for everyone. Transparent and explainable algorithms enable comprehension of system workings, while accessible information about AI usage, data, and decision-making processes is crucial.
              </p></font>
            </div>
            <br>
            <br>
            <h2>Solution:</h2>
            <div style="display: flex; align-items: center;">
              <p style="text-align: justify; flex: 1;"><font size ="4px">
                Addressing bias in AI systems is an ongoing effort that requires collaboration between data scientists, researchers, developers, and policymakers. It is crucial to develop AI systems that are fair, transparent, and accountable. By incorporating diverse perspectives, establishing rigorous evaluation metrics, and regularizing model training, bias in AI can be mitigated. Ensuring that AI systems are designed to be inclusive and unbiased will lead to more equitable outcomes and enhance trust in AI technology. Ultimately, designing AI for all means recognizing the potential for bias and taking proactive steps to address it.
              </p> </font>
              <img src="images/4-Stages-of-Ethical-AI.png" alt="vertical-align" width="380" style="margin-left: 50px;">
            </div>
            
<div class="social-media-card">
  <p class="share-text"></p>
  <div class="social-media-icons">
    <a href="https://medium.com/" target="_blank" class="social-media-medium"><i class="fab fa-medium"></i></a>
    <a href="https://www.facebook.com/" target="_blank" class="social-media-facebook"><i class="fab fa-facebook"></i></a>
    <a href="https://www.linkedin.com/signup/cold-join" target="_blank" class="social-media-linkedin"><i class="fab fa-linkedin"></i></a>
    <a href="https://twitter.com/intent/tweet?url=YOUR_BLOG_URL" target="_blank" class="social-media-twitter"><i class="fab fa-twitter"></i></a>
  </div>
</div>
<form id="subscribe-form">
  <button type="submit">Subscribe</button>
</form>
</section>       
  <div id="comment-container">
    <h2 style="text-align: center;">We would love to hear your thoughts! Please feel free to leave a comment below </h2><br><br>
    
    <form id="comment-form">
      <input type="text" id="name-input" placeholder="Your Name" required>
      <textarea id="comment-input" placeholder="Your Comment" required></textarea>
      <button type="submit">Submit</button>
    </form>
    <div id="comment-list">
      <!-- Comment items will be dynamically added here -->
    </div>
  </div>
  <script>
    document.getElementById('subscribe-form').addEventListener('submit', function(event) {
      event.preventDefault(); // Prevent the form from submitting normally
  
      // Display a popup message
      alert('Thank you for subscribing!');

     // Refresh the page and scroll to the top
     location.reload();
    window.scrollTo(0, 0);
  });
  
  </script>
<script>
  document.getElementById('subscribe-form').addEventListener('submit', function(event) {
    event.preventDefault(); // Prevent the form from submitting normally

    var email = document.getElementById('email-input').value; // Get the entered email address

    // Call the Mailchimp API to subscribe the user
    fetch('https://api.mailchimp.com/3.0/lists/{YOUR_LIST_ID}/members', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': 'apikey {YOUR_API_KEY}'
      },
      body: JSON.stringify({
        email_address: email,
        status: 'subscribed'
      })
    })
    .then(function(response) {
      if (response.ok) {
        // Subscription successful, display a success message or redirect to a thank-you page
        alert('Thank you for subscribing!');
      } else {
        // Subscription failed, display an error message
        alert('Thank you for subscribing!');
      }
    })
    .catch(function(error) {
      console.error('Error:', error);
    });
  });
</script>
<script>
    document.getElementById("comment-form").addEventListener("submit", function(event) {
  event.preventDefault(); // Prevent form submission

  // Get input values
  var name = document.getElementById("name-input").value;
  var comment = document.getElementById("comment-input").value;

  // Create new comment item
  var commentItem = document.createElement("div");
  commentItem.classList.add("comment-item");
  commentItem.innerHTML = "<strong>" + name + ":</strong> <span>" + comment + "</span>";

  // Append new comment item to the comment list
  document.getElementById("comment-list").appendChild(commentItem);

  // Clear input values
  document.getElementById("name-input").value = "";
  document.getElementById("comment-input").value = "";
});
</script>
<footer>
    <p> &copy; 2023 Akshit RamPershad. All rights reserved.</p>
    </footer>
</body>
</html>